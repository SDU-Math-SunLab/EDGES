{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import norm\n",
    "\n",
    "def EDGES(X, Y, Z, L1, lambda1, lambda2, theta1, theta2, tol, d, iterMax):\n",
    "    \"\"\"\n",
    "    EDGES: Joint decomposition model for spatial transcriptomics and scRNA-seq integration.\n",
    "\n",
    "    Parameters:\n",
    "        X      : ST data matrix (shared genes × spatial cells)\n",
    "        Y      : Shared scRNA-seq data matrix (shared genes × single cells)\n",
    "        Z      : Unique scRNA-seq data matrix (unique genes × single cells)\n",
    "        L1     : Normalized graph Laplacian (spatial adjacency constraint)\n",
    "        lambda1: Graph Laplacian regularization weight\n",
    "        lambda2: Sparsity regularization weight\n",
    "        theta1 : Weight for ST reconstruction loss\n",
    "        theta2 : Weight for unique scRNA-seq loss\n",
    "        tol    : Tolerance for convergence\n",
    "        d      : Number of latent factors\n",
    "        iterMax: Maximum number of iterations\n",
    "\n",
    "    Returns:\n",
    "        W1: Shared gene factor matrix\n",
    "        W2: Unique gene factor matrix (scRNA-seq-specific)\n",
    "        H1: ST cell embeddings\n",
    "        H2: scRNA-seq cell embeddings\n",
    "        p1: Denoised ST data matrix\n",
    "        p2: Predicted expression matrix for ST cells\n",
    "    \"\"\"\n",
    "    # Initialize matrix shapes\n",
    "    row_W1 = X.shape[0]\n",
    "    row_W2 = Z.shape[0]\n",
    "    col_H1 = X.shape[1]\n",
    "    col_H2 = Y.shape[1]\n",
    "    \n",
    "    # Random initialization with fixed seed \n",
    "    rng = np.random.RandomState(seed=42)\n",
    "    W1 = rng.rand(row_W1, d)\n",
    "    W2 = rng.rand(row_W2, d)\n",
    "    H1 = rng.rand(d, col_H1)\n",
    "    H2 = rng.rand(d, col_H2)\n",
    "\n",
    "    e1d = np.ones((1, d))\n",
    "\n",
    "    # Compute initial loss before starting iterations\n",
    "    loss_X1 = norm(X - W1 @ H1, 'fro')**2\n",
    "    loss_X2 = norm(Y - W1 @ H2, 'fro')**2\n",
    "    loss_X3 = norm(Z - W2 @ H2, 'fro')**2\n",
    "    loss_H1 = np.trace(H1 @ L1 @ H1.T)\n",
    "    loss_H = e1d @ (H1 @ H1.T) @ e1d.T + e1d @ (H2 @ H2.T) @ e1d.T\n",
    "\n",
    "    delta_init1 = theta1 * loss_X1 + loss_X2 + theta2 * loss_X3 + lambda1 * loss_H1 + lambda2 * loss_H\n",
    "    delta2 = delta_init1\n",
    "\n",
    "    # Main optimization loop\n",
    "    for iter in range(iterMax):\n",
    "        # Update W1\n",
    "        X1H1t = X @ H1.T\n",
    "        X2H2t = Y @ H2.T\n",
    "        W1H1H1t = W1 @ (H1 @ H1.T)\n",
    "        W1H2H2t = W1 @ (H2 @ H2.T)\n",
    "        W1 *= (theta1 * X1H1t + X2H2t) / (theta1 * W1H1H1t + W1H2H2t + 1e-8)\n",
    "\n",
    "        # Update H1\n",
    "        W1tX1 = W1.T @ X\n",
    "        W1tW1H1 = W1.T @ W1 @ H1\n",
    "        eddH1 = (e1d.T @ e1d) @ H1\n",
    "        H1L1 = H1 @ L1\n",
    "        H1 *= (theta1 * W1tX1) / (theta1 * W1tW1H1 + lambda2 * eddH1 + lambda1 * H1L1 + 1e-8)\n",
    "\n",
    "        # Update W2\n",
    "        X3H2t = Z @ H2.T\n",
    "        W2H2H2t = W2 @ (H2 @ H2.T)\n",
    "        W2 *= X3H2t / (W2H2H2t + 1e-8)\n",
    "\n",
    "        # Update H2\n",
    "        W1tX2 = W1.T @ Y\n",
    "        W2tX3 = W2.T @ Z\n",
    "        W1tW1H2 = W1.T @ W1 @ H2\n",
    "        W2tW2H2 = W2.T @ W2 @ H2\n",
    "        eddH2 = (e1d.T @ e1d) @ H2\n",
    "        H2 *= (W1tX2 + theta2 * W2tX3) / (W1tW1H2 + theta2 * W2tW2H2 + lambda2 * eddH2 + 1e-8)\n",
    "\n",
    "        # Compute reconstruction loss\n",
    "        loss_X1 = norm(X - W1 @ H1, 'fro')**2\n",
    "        loss_X2 = norm(Y - W1 @ H2, 'fro')**2\n",
    "        loss_X3 = norm(Z - W2 @ H2, 'fro')**2\n",
    "        loss_H1 = np.trace(H1 @ L1 @ H1.T)\n",
    "        loss_H = e1d @ (H1 @ H1.T) @ e1d.T + e1d @ (H2 @ H2.T) @ e1d.T\n",
    "\n",
    "        total_loss = (theta1 * loss_X1 + loss_X2 + theta2 * loss_X3 +\n",
    "                      lambda1 * loss_H1 + lambda2 * loss_H)\n",
    "\n",
    "        # Convergence check using relative change in loss\n",
    "        stop_value = abs((delta2 - total_loss) / (delta_init1 - total_loss + 1e-8))\n",
    "        if stop_value < tol:\n",
    "            print(f\"Converged at iteration {iter+1}\")\n",
    "            break\n",
    "\n",
    "        delta2 = total_loss\n",
    "\n",
    "    # Compute final outputs\n",
    "    p1 = W1 @ H1  # Denoised ST matrix\n",
    "    p2 = W2 @ H1  # Predicted expression matrix from unique scRNA-seq\n",
    "\n",
    "    return W1, W2, H1, H2, p1, p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing group 1...\n",
      "Converged at iteration 507\n",
      "Processing group 2...\n",
      "Converged at iteration 339\n",
      "Processing group 3...\n",
      "Converged at iteration 564\n",
      "Mean PCC: 0.4530917279449207\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# === Input Laplacian matrix ===\n",
    "L1 = pd.read_csv('Laplacian.csv')\n",
    "\n",
    "# === Hyperparameter configuration ===\n",
    "lambda1 = 10**-5      # Spatial regularization\n",
    "lambda2 = 10**1       # Sparsity regularization\n",
    "theta1 = 10**-1       # ST decomposition weight\n",
    "theta2 = 10**-4       # scRNA-seq decomposition weight\n",
    "tol = 1e-7            # Convergence tolerance\n",
    "d = 20                # Latent dimensionality\n",
    "iterMax = 600         # Maximum iterations\n",
    "\n",
    "# === Load expression matrices from CSV ===\n",
    "def load_matrix(path):\n",
    "    return pd.read_csv(path, header=0, index_col=0).values\n",
    "\n",
    "X_list = [\n",
    "    load_matrix('stdata_X11.csv'),\n",
    "    load_matrix('stdata_X12.csv'),\n",
    "    load_matrix('stdata_X13.csv')\n",
    "]\n",
    "Y_list = [\n",
    "    load_matrix('RNAdata_X21.csv'),\n",
    "    load_matrix('RNAdata_X22.csv'),\n",
    "    load_matrix('RNAdata_X23.csv')\n",
    "]\n",
    "Z_list = [\n",
    "    load_matrix('RNAdata_X31.csv'),\n",
    "    load_matrix('RNAdata_X32.csv'),\n",
    "    load_matrix('RNAdata_X33.csv')\n",
    "]\n",
    "pre_list = [\n",
    "    load_matrix('stdata_pre1.csv'),\n",
    "    load_matrix('stdata_pre2.csv'),\n",
    "    load_matrix('stdata_pre3.csv')\n",
    "]\n",
    "\n",
    "# === Run EDGES for each fold and collect inferred results ===\n",
    "st_inferr_fold = []\n",
    "for i in range(3):\n",
    "    print(f\"Processing group {i+1}...\")\n",
    "    X, Y, Z = X_list[i], Y_list[i], Z_list[i]\n",
    "    _, _, _, _, p1, p2 = EDGES(X, Y, Z, L1, lambda1, lambda2, theta1, theta2, tol, d, iterMax)\n",
    "\n",
    "    if p2.shape[0] < 2001:\n",
    "        raise ValueError(f\"Fold {i+1} p2 has fewer than 2001 rows\")\n",
    "\n",
    "    st_inferr_fold.append(p2[2000:, :])  # Slice from row index 2000 onward\n",
    "\n",
    "# === Concatenate all folds and evaluate ===\n",
    "st_infer = np.vstack(st_inferr_fold)\n",
    "st_raw = np.vstack(pre_list)\n",
    "\n",
    "# === Compute Pearson correlation coefficients between predicted and raw ST data ===\n",
    "pccs = [pearsonr(st_infer[i], st_raw[i])[0] for i in range(st_raw.shape[0])]\n",
    "print(\"Mean PCC:\", np.mean(pccs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qyguan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
